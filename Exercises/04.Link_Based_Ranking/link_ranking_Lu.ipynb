{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "If you want to normalize a vector to L1-norm or L2-norm, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-norm of [1 2 3] is [0.16666667 0.33333333 0.5       ]\n",
      "L2-norm of [1 2 3] is [0.26726124 0.53452248 0.80178373]\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function, division\n",
    "import numpy as np\n",
    "\n",
    "pr = np.array([1,2,3])\n",
    "\n",
    "def normalize(vector, norm=2):\n",
    "    return vector / np.linalg.norm(vector, norm)\n",
    "\n",
    "print(\"L1-norm of {0} is {1}\".format(pr, normalize(pr, norm=1)))\n",
    "print(\"L2-norm of {0} is {1}\".format(pr, normalize(pr, norm=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Link based ranking\n",
    "## Question 1 - Page Rank (Eigen-vector method)\n",
    "Consider a tiny Web with three pages A, B and C with no inlinks,\n",
    "and with initial PageRank = 1. Initially, none of the pages link to\n",
    "any other pages and none link to them. \n",
    "Answer the following questions, and calculate the PageRank for\n",
    "each question.\n",
    "\n",
    "1. Link page A to page B.\n",
    "2. Link all pages to each other.\n",
    "3. Link page A to both B and C, and link pages B and C to A.\n",
    "4. Use the previous links and add a link from page C to page B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: \n",
    "+ We are using the theoretical PageRank computation (without source of rank). See slide \"Transition Matrix for Random Walker\" in the lecture note. **Columns of link matrix are from-vertex, rows of link matrix are to-vertex**. We take the eigenvector with the largest eigenvalue.\n",
    "+ We only care about final ranking of the probability vector. You can choose the normalization (or not) of your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My sol\n",
    "def create_Rmatrix(L):\n",
    "    L_t = L.transpose()\n",
    "    R_t = np.array([[1/sum(c) if r else 0 for r in c] if sum(c)\n",
    "        else [0] * L_t.shape[1] for c in L_t])\n",
    "    # np.spacing(1) # suma un 'extra'\n",
    "    return R_t.transpose()\n",
    "\n",
    "def pagerank_eigen(L):\n",
    "    # Construct transition probability matrix from L\n",
    "    c_pj = L.sum(axis=0)\n",
    "    R = create_Rmatrix(L)\n",
    "    # Compute eigen-vectors and eigen-values of R\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(R)\n",
    "    # Take the eigen-vector with maximum eigen-value\n",
    "    p = eigenvectors[:,np.argmax(eigenvalues)]\n",
    "    return R, abs(normalize(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "R=[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "p=[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,0,0], \n",
    "    [1,0,0], \n",
    "    [0,0,0]\n",
    "])\n",
    "\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 None of the pages link to any other, and none link to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "R=[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "p=[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,0,0], \n",
    "    [0,0,0], \n",
    "    [0,0,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 A links to B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "R=[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "p=[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,0,0], \n",
    "    [1,0,0], \n",
    "    [0,0,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 All pages link to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION! Do we need to normalize so that the sum of probabilities is 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n",
      "R=[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "p=[0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,1,1], \n",
    "    [1,0,1], \n",
    "    [1,1,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 A links to B and C; B and C link to A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 1 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "R=[[0.  1.  1. ]\n",
      " [0.5 0.  0. ]\n",
      " [0.5 0.  0. ]]\n",
      "p=[0.5  0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,1,1], \n",
    "    [1,0,0], \n",
    "    [1,0,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 C links to B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]]\n",
      "R=[[0.  1.  0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.  0. ]]\n",
      "p=[0.44444444 0.33333333 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "L = np.array([\n",
    "    [0,1,1], \n",
    "    [1,0,1], \n",
    "    [1,0,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={}\\nR={}\\np={}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Page Rank (Iterative method)\n",
    "\n",
    "The eigen-vector method has some numerical issues (when computing eigen-vector) and not scalable with large datasets.\n",
    "\n",
    "We will apply the iterative method in the slide \"Practical Computation of PageRank\" of the lecture.\n",
    "\n",
    "Dataset for practice: https://snap.stanford.edu/data/ca-GrQc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pagerank_iterative(L, epsilon=0.001, q=0.9):\n",
    "    N = L.shape[0]\n",
    "    e_N = 1 / N * np.ones([N,1])\n",
    "    \n",
    "    # compute R\n",
    "    R = create_Rmatrix(L)\n",
    "\n",
    "    p = e_N # initialize to some vector\n",
    "    delta = 1\n",
    "    i = 0 # iteration counter\n",
    "\n",
    "    while delta > epsilon:\n",
    "        p_prev = p\n",
    "        p = q * R.dot(p) + (1 - q) * e_N\n",
    "        delta = np.linalg.norm(p - p_prev, 1)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Converged after {} iterations\".format(i))\n",
    "    print(\"Ranking vector: p={}\".format(p[:,0]))\n",
    "    return R, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct link matrix from file\n",
    "fname = \"ca-GrQc.txt\"\n",
    "\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip().split() for x in content[4:]]\n",
    "nodes = 5242\n",
    "col_a = list(set([int(x[0]) for x in content]))\n",
    "col_a.sort() \n",
    "assert(len(col_a) == nodes) # we check the length and see that all nodes are here\n",
    "\n",
    "# dictionary to get original node IDs\n",
    "dict_nodes = dict(zip(range(nodes), col_a))\n",
    "\n",
    "# dictionary to get original node IDs\n",
    "inv_dict_nodes = dict(zip(col_a, range(nodes)))\n",
    "\n",
    "L = np.zeros([nodes, nodes])\n",
    "\n",
    "for f, t in content:\n",
    "    L[inv_dict_nodes[int(t)], inv_dict_nodes[int(f)]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 30 iterations\n",
      "Ranking vector: p=[4.21393757e-04 1.90766883e-04 2.80866886e-04 ... 1.86141083e-04\n",
      " 9.90705173e-05 2.25980291e-04]\n",
      "Ranking vector: p=[4.21393757e-04 1.90766883e-04 2.80866886e-04 ... 1.86141083e-04\n",
      " 9.90705173e-05 2.25980291e-04]\n",
      "--- 19.936230659484863 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run PageRank\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "R, p = pagerank_iterative(L)\n",
    "print(\"Ranking vector: p={0}\".format(p[:,0]))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00144239]\n"
     ]
    }
   ],
   "source": [
    "print(max(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265\n"
     ]
    }
   ],
   "source": [
    "print(dict_nodes[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Hub and Authority\n",
    "\n",
    "### a)\n",
    "\n",
    "Let the adjacency matrix for a graph of four vertices ($n_1$ to $n_4$) be\n",
    "as follows:\n",
    "\n",
    "$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "\t0 & 1 & 1 & 1  \\\\\n",
    "\t0 & 0 & 1 & 1 \\\\\n",
    "\t1 & 0 & 0 & 1 \\\\\n",
    "\t0 & 0 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Calculate the authority and hub scores for this graph using the\n",
    "HITS algorithm with k = 6, and identify the best authority and\n",
    "hub nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION! Shouldn't A have the largest Authority score? (since it's the one with more incoming links!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[0,1,1,1],[0,0,1,1],[1,0,0,1],[0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hits_iterative(A, k=6, delta=0.001):\n",
    "    n = A.shape[0]\n",
    "    a = 1 / n**2 * np.ones(n)\n",
    "    h = a.copy()\n",
    "    a_new = None\n",
    "    h_new = None\n",
    "\n",
    "    for i in range(k):\n",
    "        a_new = A @ h\n",
    "        h_new = a @ A\n",
    "        delta_a = np.linalg.norm(a_new - a, 1)\n",
    "        delta_h = np.linalg.norm(h_new - h, 1)\n",
    "        a = normalize(a_new.copy(), 2)\n",
    "        h = normalize(h_new.copy(), 2)\n",
    "        if delta_a <= delta and delta_h <= delta:\n",
    "            break\n",
    "\n",
    "    return a, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70710678, 0.47140452, 0.47140452, 0.23570226]),\n",
       " array([0.21320072, 0.21320072, 0.42640143, 0.85280287]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_iterative(A, delta=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, h = hits_iterative(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535797066992358"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058737503296141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Apply the HITS algorithm to the dataset: https://snap.stanford.edu/data/ca-GrQc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct link matrix from file\n",
    "fname = \"ca-GrQc.txt\"\n",
    "\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip().split() for x in content[4:]]\n",
    "nodes = 5242\n",
    "col_a = list(set([int(x[0]) for x in content]))\n",
    "col_a.sort() \n",
    "assert(len(col_a) == nodes) # we check the length and see that all nodes are here\n",
    "\n",
    "# dictionary to get original node IDs\n",
    "dict_nodes = dict(zip(range(nodes), col_a))\n",
    "\n",
    "# dictionary to get original node IDs\n",
    "inv_dict_nodes = dict(zip(col_a, range(nodes)))\n",
    "\n",
    "L = np.zeros([nodes, nodes])\n",
    "\n",
    "for f, t in content:\n",
    "    L[inv_dict_nodes[int(t)], inv_dict_nodes[int(f)]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, h = hits_iterative(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1158500753831797"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21012"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_nodes[np.argmax(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11585007538317971"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21012"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_nodes[np.argmax(h)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** We follow the slide \"HITS algorithm\" in the lecture. **Denote $x$ as authority vector and $y$ as hub vector**. You can use matrix multiplication for the update steps in the slide \"Convergence of HITS\". Note that rows of adjacency matrix is from-vertex and columns of adjacency matrix is to-vertex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Ranking Methodology (Hard)\n",
    "\n",
    "1 Give a directed graph, as small as possible, satisfying all the properties mentioned below:\n",
    "1. There exists a path from node i to node j for all nodes i,j in the directed graph. Recall, with this property the jump to an arbitrary node in PageRank is not required, so that you can set q = 1 (refer lecture slides).\n",
    "\n",
    "2. HITS authority ranking and PageRank ranking of the graph nodes are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Give intuition/methodology on how you constructed such a directed graph with the properties described in (a).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Are there specific graph structures with arbitrarily large instances where PageRank ranking and HITS authority ranking are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
